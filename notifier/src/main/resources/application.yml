server:
  port: 8080

spring:
  application:
    name: notifier
  kafka:
    topic:
      webhook-event:
        name: ${WEBHOOK_EVENT_TOPIC:webhook-events}
        partitions: ${WEBHOOK_EVENT_TOPIC_PARTITIONS:3}
        replication-factor: ${WEBHOOK_EVENT_TOPIC_REPLICATION_FACTOR:1}
      dead-letter-queue-topic:
        name: ${WEBHOOK_EVENT_DEAD_LETTER_QUEUE_TOPIC:webhook-event-dead-letter-queue}
        partitions: ${WEBHOOK_EVENT_DEAD_LETTER_QUEUE_TOPIC_PARTITIONS:3}
        replication-factor: ${WEBHOOK_EVENT_DEAD_LETTER_QUEUE_TOPIC_REPLICATION_FACTOR:1}
    bootstrap-servers: ${BOOTSTRAP_SERVERS_CONFIG:localhost:9092}
    consumer:
      group-id: event-processing-group
      auto-offset-reset: earliest
      enable-auto-commit: false # We will manually commit after processing
      poll-timeout: 3000
      max-poll-records: 20
    listener:
      concurrency: 1
    producer:
      retries: 5
      acks: all
      properties:
        delivery.timeout.ms: 30000   # Max time before message fails
        request.timeout.ms: 5000     # Timeout for broker response
        retry.backoff.ms: 500        # Time between retries
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:5432/webhook
    username: ${DB_USER:postgre}
    password: ${DB_PASSWORD:postgre}
    driver-class-name: org.postgresql.Driver
  jpa:
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    hibernate:
      ddl-auto: update
    show-sql: true

  redis:
    host: ${REDIS_HOST:localhost}
    port: ${REDIS_PORT:6379}
    limit:
      event: 100
      time: 1 #minute

resilience4j:
  retry:
    instances:
      webhookRetry:
        max-attempts: 5
        wait-duration: 2s
        exponential-backoff-multiplier: 2
  circuitbreaker:
    instances:
      webhookCircuitBreaker:
        failureRateThreshold: 50
        slowCallRateThreshold: 60
        slowCallDurationThreshold: 2s
        waitDurationInOpenState: 10s
        permittedNumberOfCallsInHalfOpenState: 3
        minimumNumberOfCalls: 5
        event-consumer-buffer-size: 10

management:
  endpoints:
    web:
      exposure:
        include: "*"
  metrics:
    export:
      prometheus:
        enabled: true

thread-pool:
  kafka-consumer:
    core-size: 10
    max-size: 50
    queue-capacity: 100